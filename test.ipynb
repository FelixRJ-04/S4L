{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\UASLP -Semestre 11\\TRADUCTOR\\S4L\\env\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "copy",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 72\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hand_landmarks \u001b[38;5;129;01min\u001b[39;00m hands_r\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks:\n\u001b[0;32m     65\u001b[0m     mp_drawing\u001b[38;5;241m.\u001b[39mdraw_landmarks(\n\u001b[0;32m     66\u001b[0m     image,\n\u001b[0;32m     67\u001b[0m     hand_landmarks,\n\u001b[0;32m     68\u001b[0m     mp_hands\u001b[38;5;241m.\u001b[39mHAND_CONNECTIONS,\n\u001b[0;32m     69\u001b[0m     mp_drawing\u001b[38;5;241m.\u001b[39mDrawingSpec(color\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), thickness\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, circle_radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m     70\u001b[0m     mp_drawing\u001b[38;5;241m.\u001b[39mDrawingSpec(color\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m), thickness\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m---> 72\u001b[0m     combined_landmarks\u001b[38;5;241m=\u001b[39m \u001b[43mpose_r\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpose_landmarks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m()\n\u001b[0;32m     74\u001b[0m     hand_landmarks_indices_to_exclude \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, landmark \u001b[38;5;129;01min\u001b[39;00m hand_landmarks_indices_to_exclude:\n",
      "\u001b[1;31mAttributeError\u001b[0m: copy"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "#Inicialización de MediaPipe con sus utilidades para dibujo\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_hands= mp.solutions.hands\n",
    "\n",
    "pose = mp_pose.Pose()\n",
    "hands =mp_hands.Hands()\n",
    "\n",
    "#Inicialización de captura de video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#Configuración del modelo Holistic\n",
    "with mp_holistic.Holistic(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as holistic:\n",
    "\n",
    " while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      print(\"Ignorando el frame vacio de la camara.\")\n",
    "      continue\n",
    "  \n",
    "    pose_r= pose.process(image)\n",
    "    hands_r=hands.process(image)\n",
    "    \n",
    "    #Se prepara la imagen para el procesamiento\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = holistic.process(image)\n",
    "\n",
    "    # Conversión de imagen a BGR para su muestreo\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    #Detección de rostro\n",
    "    if results.face_landmarks:\n",
    "      mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        results.face_landmarks,\n",
    "        mp_holistic.FACEMESH_CONTOURS,\n",
    "        landmark_drawing_spec = None,\n",
    "        connection_drawing_spec = mp_drawing_styles\n",
    "        .get_default_face_mesh_contours_style())\n",
    "      \n",
    "    \n",
    "    #Detección y dibujo del cuerpo (pose)\n",
    "    if pose_r.pose_landmarks:\n",
    "      mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        pose_r.pose_landmarks,\n",
    "        mp_pose.POSE_CONNECTIONS,\n",
    "        landmark_drawing_spec = mp_drawing_styles\n",
    "        .get_default_pose_landmarks_style())\n",
    "      \n",
    "\n",
    "    #Detección y dibujo de las manos\n",
    "    if hands_r.multi_hand_landmarks:\n",
    "        for hand_landmarks in hands_r.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            hand_landmarks,\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),\n",
    "            mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2))\n",
    "            \n",
    "            combined_landmarks= pose_r.pose_landmarks.copy()\n",
    "            \n",
    "            hand_landmarks_indices_to_exclude = range(0,5)\n",
    "            \n",
    "            for i, landmark in hand_landmarks_indices_to_exclude:\n",
    "                if i not in hand_landmarks_indices_to_exclude:\n",
    "                    combined_landmarks.append(landmark)\n",
    "            \n",
    "            mp_drawing.draw_landmarks(\n",
    "            image,\n",
    "            combined_landmarks,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),\n",
    "            mp_drawing.DrawingSpec(color=(255, 255, 255), thickness=2))\n",
    "            cv2.imshow('X', combined_landmarks)\n",
    "            \n",
    "    # Muestreo de camara con modelos ya cargados\n",
    "    cv2.imshow('MediaPipe Holistic y Hand Tracker', image)\n",
    "\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
